{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46179f7c-fbf9-43e7-9696-7b03533d275e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\vrishank\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\object_detection-0.1-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at c:\\users\\vrishank\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\pyparsing-2.4.7-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at c:\\users\\vrishank\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\sacrebleu-2.2.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fbd2ca1-ec71-4c08-b3c2-f8bfb216bb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vrishank\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb96b7df23af4ae5b752495d0c38be73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 13:20:55 INFO: Downloaded file to C:\\Users\\Vrishank\\stanza_resources\\resources.json\n",
      "2025-06-24 13:20:55 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-06-24 13:20:56 INFO: File exists: C:\\Users\\Vrishank\\stanza_resources\\en\\default.zip\n",
      "2025-06-24 13:21:01 INFO: Finished downloading models and saved to C:\\Users\\Vrishank\\stanza_resources\n",
      "2025-06-24 13:21:01 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74c542a5f674651ab7b9ad658087e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 13:21:01 INFO: Downloaded file to C:\\Users\\Vrishank\\stanza_resources\\resources.json\n",
      "2025-06-24 13:21:01 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-06-24 13:21:02 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| mwt          | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "======================================\n",
      "\n",
      "2025-06-24 13:21:02 INFO: Using device: cpu\n",
      "2025-06-24 13:21:02 INFO: Loading: tokenize\n",
      "2025-06-24 13:21:05 INFO: Loading: mwt\n",
      "2025-06-24 13:21:05 INFO: Loading: pos\n",
      "2025-06-24 13:21:07 INFO: Loading: constituency\n",
      "2025-06-24 13:21:08 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "from nltk import Tree\n",
    "\n",
    "stanza.download('en')\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0cd3b3-23ee-403c-8600-982f5d79ef8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ROOT                                                                          \n",
      "         |                                                                             \n",
      "         S                                                                            \n",
      "         |                                                                             \n",
      "         VP                                                                           \n",
      "   ______|____                                                                         \n",
      "  |           NP                                                                      \n",
      "  |       ____|_______________                                                         \n",
      "  |      |                    PP                                                      \n",
      "  |      |     _______________|_______________                                         \n",
      "  |      |    |                               NP                                      \n",
      "  |      |    |           ____________________|________                                \n",
      "  |      |    |          |                             VP                             \n",
      "  |      |    |          |              _______________|____________                   \n",
      "  |      |    |          |             |          PP                PP                \n",
      "  |      |    |          |             |       ___|____       ______|_____             \n",
      "  |      NP   |          NP            |      |        NP    |            NP          \n",
      "  |      |    |      ____|____         |      |        |     |       _____|______      \n",
      "  VB    NNS   IN    NN        NN      VBN     IN      NNP    IN     JJ           NN   \n",
      "  |      |    |     |         |        |      |        |     |      |            |     \n",
      "delete files with inode     number specified  by     REGEX under current     directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"delete files with inode number specified by REGEX under current directory\")\n",
    "tree = Tree.fromstring(str(doc.sentences[0].constituency))\n",
    "tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d74ccc0e-4a27-4b2a-a959-aaff54b6154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 'delete' → Phrase: 'delete files with inode number specified by REGEX under current directory' (Type: VP)\n",
      "Word: 'files' → Phrase: 'files' (Type: NP)\n",
      "Word: 'with' → Phrase: 'with inode number specified by REGEX under current directory' (Type: PP)\n",
      "Word: 'inode' → Phrase: 'inode number' (Type: NP)\n",
      "Word: 'number' → Phrase: 'inode number' (Type: NP)\n",
      "Word: 'specified' → Phrase: 'specified by REGEX under current directory' (Type: VP)\n",
      "Word: 'by' → Phrase: 'by REGEX' (Type: PP)\n",
      "Word: 'REGEX' → Phrase: 'REGEX' (Type: NP)\n",
      "Word: 'under' → Phrase: 'under current directory' (Type: PP)\n",
      "Word: 'current' → Phrase: 'current directory' (Type: NP)\n",
      "Word: 'directory' → Phrase: 'current directory' (Type: NP)\n"
     ]
    }
   ],
   "source": [
    "def get_node_phrases(tree, depth = 2):\n",
    "    leaf_positions = tree.treepositions('leaves')\n",
    "    word_to_phrase = []\n",
    "\n",
    "    for pos in leaf_positions:\n",
    "        try:\n",
    "            # Go up two levels from the leaf\n",
    "            parent_1 = pos[:-1]       # immediate parent\n",
    "            parent_2 = pos[:-2]\n",
    "            if depth == 2: # two levels up\n",
    "                phrase_subtree = tree[parent_2]\n",
    "            elif depth == 1: \n",
    "                phrase_subtree = tree[parent_1]\n",
    "            phrase = \" \".join(phrase_subtree.leaves())\n",
    "            word = tree[pos]\n",
    "            word_to_phrase.append((word, phrase, phrase_subtree.label()))\n",
    "        except IndexError:\n",
    "            # Skip if not enough levels\n",
    "            continue\n",
    "\n",
    "    return word_to_phrase\n",
    "\n",
    "phrases_data = get_node_phrases(tree)\n",
    "\n",
    "for word, phrase, label in phrases_data:\n",
    "    print(f\"Word: '{word}' → Phrase: '{phrase}' (Type: {label})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23c0f4e9-d2fa-4c51-93a2-2993c16c6a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['delete files with inode number specified by REGEX under current directory',\n",
       " 'files',\n",
       " 'with inode number specified by REGEX under current directory',\n",
       " 'inode number',\n",
       " 'inode number',\n",
       " 'specified by REGEX under current directory',\n",
       " 'by REGEX',\n",
       " 'REGEX',\n",
       " 'under current directory',\n",
       " 'current directory',\n",
       " 'current directory']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = []\n",
    "for word, phrase, label in phrases_data:\n",
    "    phrases.append(phrase)\n",
    "\n",
    "phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b62b8-6aa4-42ec-8e34-0fa682c136eb",
   "metadata": {},
   "source": [
    "Now that we have that,\n",
    "* remove the phrases with more than 4 words. \n",
    "* add the missing words in the right order. (\"delete\" is missing here)\n",
    "* remove duplicate phrases\n",
    "* remove redundant phrases (\"by REGEX\" and \"REGEX\", \"current directory\" and \"under current directory\")\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2662a7b3-c59d-4ba2-9cf9-e72de9ccf3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files',\n",
       " 'inode number',\n",
       " 'inode number',\n",
       " 'by REGEX',\n",
       " 'REGEX',\n",
       " 'under current directory',\n",
       " 'current directory',\n",
       " 'current directory']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove phrases with more than 4 words\n",
    "for i, phrase in enumerate(phrases):\n",
    "    if len(phrase.split()) > 4:\n",
    "        del phrases[i]\n",
    "\n",
    "phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c7a4a76-7d90-4cd6-822b-c2e208441424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files',\n",
       " 'inode number',\n",
       " 'by REGEX',\n",
       " 'REGEX',\n",
       " 'under current directory',\n",
       " 'current directory']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicate phrases\n",
    "for i,phrase1 in enumerate(phrases):\n",
    "    for j,phrase2 in enumerate(phrases):\n",
    "        if j <= i:\n",
    "            continue\n",
    "\n",
    "        if phrase1 == phrase2:\n",
    "            del phrases[j]\n",
    "\n",
    "phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7369be-1d6a-4ece-914a-1e90614aca63",
   "metadata": {},
   "source": [
    "whats left:\n",
    "* remove redundant phrases (\"by REGEX\" and \"REGEX\", \"current directory\" and \"under current directory\")\n",
    "* add the missing words in the right order. (\"delete\" is missing here)\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e1de3cf-38b9-4402-88ec-1024d96c171a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files', 'inode number', 'by REGEX', 'under current directory']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove redundant phrases\n",
    "phrases = [\n",
    "    p for p in phrases\n",
    "    if not any(p != q and p in q for q in phrases)\n",
    "]\n",
    "phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0de3773c-f5d4-46b9-b159-5b170d27003d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 'delete' → Phrase: 'delete' (Type: VB)\n",
      "Word: 'files' → Phrase: 'files' (Type: NNS)\n",
      "Word: 'with' → Phrase: 'with' (Type: IN)\n",
      "Word: 'inode' → Phrase: 'inode' (Type: NN)\n",
      "Word: 'number' → Phrase: 'number' (Type: NN)\n",
      "Word: 'specified' → Phrase: 'specified' (Type: VBN)\n",
      "Word: 'by' → Phrase: 'by' (Type: IN)\n",
      "Word: 'REGEX' → Phrase: 'REGEX' (Type: NNP)\n",
      "Word: 'under' → Phrase: 'under' (Type: IN)\n",
      "Word: 'current' → Phrase: 'current' (Type: JJ)\n",
      "Word: 'directory' → Phrase: 'directory' (Type: NN)\n"
     ]
    }
   ],
   "source": [
    "# add missing words in the right order\n",
    "\n",
    "words = []\n",
    "words_data = get_node_phrases(tree, depth=1)\n",
    "for word, phrase, label in words_data:\n",
    "    print(f\"Word: '{word}' → Phrase: '{phrase}' (Type: {label})\")\n",
    "    words.append(phrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa8593b8-83fb-42dc-a868-36dc43933625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['delete',\n",
       " 'files',\n",
       " 'with',\n",
       " 'inode',\n",
       " 'number',\n",
       " 'specified',\n",
       " 'by',\n",
       " 'REGEX',\n",
       " 'under',\n",
       " 'current',\n",
       " 'directory']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a026b3a-7d75-456a-87f1-576fc54c773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_tokens = {tuple(p.split()): p for p in phrases}\n",
    "\n",
    "result = []\n",
    "i = 0\n",
    "while i < len(words):\n",
    "    for length in range(len(words), 0, -1):\n",
    "        slice_ = tuple(words[i:i+length])\n",
    "        if slice_ in phrase_tokens:\n",
    "            result.append(phrase_tokens[slice_])\n",
    "            i += length\n",
    "            break\n",
    "    else:\n",
    "        result.append(words[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74169ad4-9414-4ca6-8466-eee25d4b31df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['delete',\n",
       " 'files',\n",
       " 'with',\n",
       " 'inode number',\n",
       " 'specified',\n",
       " 'by REGEX',\n",
       " 'under current directory']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046178ac-d9e2-4c9c-81a7-404406d65e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
